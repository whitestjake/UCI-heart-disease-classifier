{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category features\n",
    "cont_cols  = ['age', 'chol', 'oldpeak', 'thalch', 'trestbps']\n",
    "cat_cols = ['ca', 'cp', 'restecg', 'slope', 'thal', 'sex', 'fbs', 'exang']\n",
    "\n",
    "#read training data, normalize continous features using (X - mean) / std\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "\n",
    "# Create a new dataframe from original and change all target variables greater than 0 to 1, instead of 1,2,3,4,5\n",
    "df_fix = df\n",
    "df_fix['num'] = np.where(df_fix['num'] > 0, 1, 0)\n",
    "\n",
    "# Seperate features (X) and target (y)\n",
    "X = df_fix.drop(columns=['id', 'num', 'dataset'])\n",
    "y = df_fix['num']\n",
    "\n",
    "# Replace missing data in categorical columns with unknown\n",
    "for cols in cat_cols:\n",
    "    X[cols] = X[cols].fillna('Unknown')\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "# Convert continuous column values to float\n",
    "X[cont_cols] = X.loc[:, cont_cols].astype('float64')\n",
    "\n",
    "# find the mean and standard deviation of each continuous column\n",
    "train_means = X[cont_cols].mean()\n",
    "train_std = X[cont_cols].std()\n",
    "\n",
    "# replace any missing value in a continuous column with the mean of that column\n",
    "X.loc[:, cont_cols] = X[cont_cols].fillna(train_means)\n",
    "\n",
    "# Normalize data\n",
    "X.loc[:, cont_cols] = (X.loc[:, cont_cols] - train_means) / train_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data before splitting for randomized train, valid, test sets\n",
    "shuffled = df_fix.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# separate data into training and testing sets\n",
    "train_split = int(0.6 * len(X))\n",
    "X_train = X[:train_split]\n",
    "X_test = X[train_split:]\n",
    "\n",
    "y_train = y[:train_split]\n",
    "y_test = y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB algorithm\n",
    "\n",
    "#calculate catogorical feature probability\n",
    "def calcCatProb(x, p):\n",
    "    \"\"\"\n",
    "    x: feature value (0 or 1 since one-hot encoded)\n",
    "    p: probability of feature=1 given class\n",
    "    \"\"\"\n",
    "    return p if x == 1 else (1 - p)\n",
    "    \n",
    "#calculate continous feature probability using Maximum Likelihood estimator for Gaussian Distribution\n",
    "def calcGaussProb(x, mean, var):\n",
    "    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(- (x - mean) ** 2 / (2 * var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier\n",
    "def naiveBayes(X_train, y_train):\n",
    "    model = {} #store all learned parameters\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    # where y_train is equal to expected result, assign X_train row to X_c, after looping through all the classes\n",
    "    # returns model as the fully trained dictionary\n",
    "    for c in classes:\n",
    "        X_c = X_train[y_train == c]\n",
    "        model[c] = {\n",
    "            \"prior\": len(X_c) / len(X_train),\n",
    "            \"mean\": X_c[cont_cols].mean(),\n",
    "            \"var\": X_c[cont_cols].var() + 1e-6,\n",
    "            \"cat_probs\": {}\n",
    "        }\n",
    "\n",
    "        # categorical probs (Bernoulli for one-hot encoded columns)\n",
    "        for col in X_train.drop(columns=cont_cols).columns:\n",
    "            model[c][\"cat_probs\"][col] = X_c[col].mean()\n",
    "\n",
    "    return model\n",
    "\n",
    "def predictSingle(row, model):\n",
    "    posteriors = {}\n",
    "    for c, params in model.items():\n",
    "        # Start with log prior\n",
    "        log_prob = np.log(params[\"prior\"])\n",
    "        \n",
    "        # Continuous features (Gaussian)\n",
    "        for col in cont_cols:\n",
    "            mean = params[\"mean\"][col]\n",
    "            var = params[\"var\"][col]\n",
    "            prob = calcGaussProb(row[col], mean, var)\n",
    "            log_prob += np.log(prob + 1e-9)\n",
    "\n",
    "        # Categorical features (Bernoulli)\n",
    "        for col, p in params[\"cat_probs\"].items():\n",
    "            prob = calcCatProb(row[col], p)\n",
    "            log_prob += np.log(prob + 1e-9)\n",
    "\n",
    "        posteriors[c] = log_prob\n",
    "\n",
    "    return max(posteriors, key=posteriors.get)\n",
    "\n",
    "def naiveBayesPredict(X_test, model):\n",
    "    return np.array([predictSingle(row, model) for _, row in X_test.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               Actual\n",
      "             1       0\n",
      "P       +--------+--------+\n",
      "r     1 | TP=209 | FP=16  |\n",
      "e       +--------+--------+\n",
      "d     0 | FN=100 | TN=43  |\n",
      ".       +--------+--------+\n",
      "\n",
      "Accuracy:   0.68478\n",
      "Precison:   0.92889\n",
      "Recall:     0.67638\n",
      "F-Score:  0.78277\n"
     ]
    }
   ],
   "source": [
    "# Print results of Naive Bayes classifier\n",
    "\n",
    "def printConfusionMatrix(tp, fp, tn, fn):\n",
    "    print(\"\\n%15sActual\" % \"\")\n",
    "    print(\"%6s %7s %7s\" % (\"\", \"1\", \"0\"))\n",
    "    print(\"P%6s +--------+--------+\" % \"\")\n",
    "    print(\"r%6s | %-6s | %-6s |\" % (\"1\", 'TP='+str(tp), 'FP='+str(fp)))\n",
    "    print(\"e%6s +--------+--------+\" % \"\")\n",
    "    print(\"d%6s | %-6s | %-6s |\" % (\"0\", 'FN='+str(fn), 'TN='+str(tn)))\n",
    "    print(\".%6s +--------+--------+\\n\" % \"\")\n",
    "\n",
    "def getConfusionMatrix(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def getAccuracy(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn) \n",
    "\n",
    "def getPrecision(tp, fp, tn, fn):\n",
    "    return tp / (tp + fp + 1e-9)\n",
    "\n",
    "def getRecall(tp, fp, tn, fn):\n",
    "    return tp / (tp + fn + 1e-9) \n",
    "\n",
    "def getFScore(tp, fp, tn, fn):\n",
    "    precision = getPrecision(tp, fp, tn, fn)\n",
    "    recall = getRecall(tp, fp, tn, fn)\n",
    "    return 2 * precision * recall / (precision + recall + 1e-9) \n",
    "\n",
    "model = naiveBayes(X_train, y_train)\n",
    "y_pred = naiveBayesPredict(X_test, model)\n",
    "\n",
    "tp, fp, tn, fn = getConfusionMatrix(y_test.values, y_pred)\n",
    "printConfusionMatrix(tp, fp, tn, fn)\n",
    "\n",
    "print('Accuracy:  %8.5f' % getAccuracy(tp, fp, tn, fn))\n",
    "print('Precison:  %8.5f' % getPrecision(tp, fp, tn, fn))\n",
    "print('Recall:    %8.5f' % getRecall(tp, fp, tn, fn))\n",
    "print('F-Score: %8.5f' % getFScore(tp, fp, tn, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
